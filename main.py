# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1k0Whvm4F4eN8Dy0w86SrQ4V3i-vg0eex

# Importing all dependencies
"""

from google.colab import drive
drive.mount('/content/drive')
import seaborn as sns
from matplotlib import pyplot as plt
from sklearn.model_selection import cross_val_score

import numpy as np

from sklearn import datasets
from sklearn.model_selection import cross_val_predict
from sklearn import linear_model
import pandas as pd

!unzip "/content/drive/MyDrive/ml_speedrun/train.csv.zip"

### reading csv file

train = pd.read_csv("/content/train.csv")
train.head()

"""# Dropping null values"""

train.dropna(how='all')

##spliiting features


X = train.drop(columns = ["glasses"])
Y = train["glasses"]

"""# Let's Observe the data

# Value of Variable X
"""

X.head()

"""# Value of Y"""

Y.head()

"""### Data Visualization"""

import sklearn.model_selection as model_selection

train_x, test_x, train_y, test_y = model_selection.train_test_split(X, Y, shuffle=True, test_size=0.2, random_state = 3)

print(train_x.shape, train_y.shape, test_x.shape, test_y.shape)

"""## Let's see the values of images with glasses and with no glasses"""

plt.hist(train["glasses"])
print("Number of no-glass images",np.count_nonzero(train["glasses"]))
print("Number of imges with images",len(train["glasses"])-np.count_nonzero(train["glasses"]))

"""### Using Random forest classifier"""

from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators = 7)  
  
clf1=clf.fit(train_x, train_y)

"""# Cross-Validation for random forest classifier"""

cv1=cross_val_score(clf1, X, Y,cv=5)
print("Cross Validation score for Random Forest Classifier is :",cv1)
print('Mean Value Error', cv1.mean())

scores = pd.DataFrame(cv1,columns=['Scores'])
sns.set(style="white", rc={"lines.linewidth": 3})
sns.barplot(x=['Iter1','Iter2','Iter3','Iter4','Iter5'],y="Scores",data=scores)
plt.show()
sns.set()

"""# Let's Calclate the Accuracies for the Random Forest Classifier"""

# performing predictions on the test dataset
y_pred = clf.predict(test_x)
  
# metrics are used to find accuracy or error
from sklearn import metrics  

  
# using metrics module for accuracy calculation
print("ACCURACY OF THE MODEL: ", metrics.accuracy_score(test_y, y_pred))

"""### Apply Prinicipal Component Analysis for dimensionality reduction"""

from sklearn.decomposition import PCA

pca = PCA(.90)

pca = PCA(n_components=256)
X_PCA = pca.fit(train_x).transform(train_x)

clf = RandomForestClassifier(n_estimators = 7)  
  
clf.fit(X_PCA, train_y)

"""# Let's find the accuracies now after applying PCA"""

test_X_pca = pca.fit(test_x).transform(test_x)

# performing predictions on the test dataset
y_pred = clf.predict(test_X_pca)
  
# metrics are used to find accuracy or error
from sklearn import metrics  
print()
  
# using metrics module for accuracy calculation
print("ACCURACY OF THE MODEL: ", metrics.accuracy_score(test_y, y_pred))

"""### Let's apply Logistic regression on given dataset"""

from sklearn.linear_model import LogisticRegression
print()
clf2 = LogisticRegression(random_state=0).fit(train_x, train_y)
y_pred_lr = clf2.predict(test_x)

"""# Cross-Validation for Logistic Regression Model"""

cv2=cross_val_score(clf2, X, Y,cv=5)
print("Cross Validation score for Logistic Regression Model is :",cv2)
print('Mean Value Error', cv2.mean())

scores = pd.DataFrame(cv2,columns=['Scores'])
sns.set(style="white", rc={"lines.linewidth": 3})
sns.barplot(x=['Iter1','Iter2','Iter3','Iter4','Iter5'],y="Scores",data=scores)
plt.show()
sns.set()

"""Let's Calculate the accuracy for Logistic regression"""

from sklearn.metrics import accuracy_score
print(accuracy_score(test_y,y_pred_lr))

"""# Apply LDA(Linear Discriminant Analysis) on given dataset"""

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
import matplotlib.pyplot as plt

lda = LinearDiscriminantAnalysis(n_components=2)
clf3=lda.fit(train_x, train_y)
X_LDA = clf3.transform(train_x)

"""# Cross-Validation for Linear Discriminant Analysis"""

cv3=cross_val_score(clf3, X, Y,cv=5)
print("Cross Validation score for Random Forest Classifier is :",cv3)
print('Mean Value Error', cv3.mean())

scores = pd.DataFrame(cv3,columns=['Scores'])
sns.set(style="white", rc={"lines.linewidth": 3})
sns.barplot(x=['Iter1','Iter2','Iter3','Iter4','Iter5'],y="Scores",data=scores)
plt.show()
sns.set()

Z = lda.transform(test_x) #using the model to project Z
z_labels = lda.predict(test_x) #gives you the predicted label for each sample
z_prob = lda.predict_proba(test_x) #the probability of each sample to belong to each class

import numpy as np

pred_lda = []

for i in z_prob:
  pred_lda.append(np.argmax(i))

pred_lda = np.array(pred_lda)

pred_lda.shape

"""# Let's Calculatethe accuracy for the LDA"""

print(accuracy_score(test_y,pred_lda))